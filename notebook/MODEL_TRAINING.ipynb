{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143aff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, joblib, json\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (precision_recall_fscore_support, average_precision_score,\n",
    "                             precision_recall_curve, roc_auc_score)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "\n",
    "ART = Path(\"../artifacts\")\n",
    "ART.mkdir(exist_ok=True)\n",
    "# Load data from existing artifacts directory\n",
    "df = pd.read_csv(ART / \"creditcard.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a4256",
   "metadata": {},
   "source": [
    "TEST-TRAIN Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf0bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class'].astype(int)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "pd.concat([X_train, y_train], axis=1).to_csv(ART/\"train.csv\", index=False)\n",
    "pd.concat([X_test, y_test], axis=1).to_csv(ART/\"test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d4288",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b796e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../artifacts/preprocessor.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_cols = ['Time','Amount']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('scale', StandardScaler(), num_cols)],\n",
    "    remainder='passthrough',  \n",
    ")\n",
    "\n",
    "X_train_p = preprocessor.fit_transform(X_train)\n",
    "X_val_p   = preprocessor.transform(X_val)\n",
    "X_test_p  = preprocessor.transform(X_test)\n",
    "\n",
    "joblib.dump(preprocessor, ART/\"preprocessor.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351709d9",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154bdf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB PR-AUC: 0.8346189169786565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../artifacts/xgb_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = y_train.sum()\n",
    "neg = len(y_train) - pos\n",
    "spw = neg / pos  \n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=spw,\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "xgb.fit(X_train_p, y_train)\n",
    "xgb_val_proba = xgb.predict_proba(X_val_p)[:,1]\n",
    "print(\"XGB PR-AUC:\", average_precision_score(y_val, xgb_val_proba))\n",
    "joblib.dump(xgb, ART/\"xgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c7948",
   "metadata": {},
   "source": [
    "Neural Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a04c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: loss 0.7334\n",
      "epoch 4: loss 0.7035\n",
      "epoch 6: loss 0.6753\n",
      "epoch 8: loss 0.6490\n",
      "epoch 10: loss 0.6227\n",
      "NN PR-AUC: 0.015046340858149175\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_in):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_in, 64), nn.ReLU(),\n",
    "            nn.BatchNorm1d(64), nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32), nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "d_in = X_train_p.shape[1]\n",
    "nn_model = MLP(d_in)\n",
    "\n",
    "# class weights\n",
    "pos_weight = torch.tensor([spw], dtype=torch.float32)  # weight positive errors higher\n",
    "criterion = nn.BCELoss()  # alternative: BCEWithLogitsLoss(pos_weight=pos_weight) w/o Sigmoid\n",
    "\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=1e-3)\n",
    "Xtr_t = torch.tensor(X_train_p, dtype=torch.float32)\n",
    "ytr_t = torch.tensor(y_train.values.reshape(-1,1), dtype=torch.float32)\n",
    "\n",
    "for epoch in range(10):\n",
    "    nn_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = nn_model(Xtr_t)\n",
    "    loss = criterion(out, ytr_t)\n",
    "    loss.backward(); optimizer.step()\n",
    "    if (epoch+1)%2==0: print(f\"epoch {epoch+1}: loss {loss.item():.4f}\")\n",
    "\n",
    "# validation probabilities\n",
    "nn_model.eval()\n",
    "Xval_t = torch.tensor(X_val_p, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    nn_val_proba = nn_model(Xval_t).cpu().numpy().ravel()\n",
    "\n",
    "print(\"NN PR-AUC:\", average_precision_score(y_val, nn_val_proba))\n",
    "torch.save(nn_model.state_dict(), ART/\"nn_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c93e2",
   "metadata": {},
   "source": [
    "Probability Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513c934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated XGB PR-AUC: 0.8346189169786565\n",
      "Calibrated NN  PR-AUC: 0.00816974137096763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def platt_calibrate(probs, y_true):\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(probs.reshape(-1,1), y_true)\n",
    "    def calibrator(p):\n",
    "        return lr.predict_proba(p.reshape(-1,1))[:,1]\n",
    "    return calibrator, lr\n",
    "\n",
    "xgb_cal, xgb_lr = platt_calibrate(xgb_val_proba, y_val)\n",
    "nn_cal, nn_lr   = platt_calibrate(nn_val_proba, y_val)\n",
    "\n",
    "\n",
    "print(\"Calibrated XGB PR-AUC:\", average_precision_score(y_val, xgb_cal(xgb_val_proba)))\n",
    "print(\"Calibrated NN  PR-AUC:\", average_precision_score(y_val, nn_cal(nn_val_proba)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2586c94",
   "metadata": {},
   "source": [
    "Weighted Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e8d78c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ensemble weight (XGB=1.00, NN=0.00), PR-AUC=0.8346\n"
     ]
    }
   ],
   "source": [
    "def weighted_ensemble(xgb_p, nn_p, w):\n",
    "    \"\"\"Linear ensemble of two models.\"\"\"\n",
    "    return w * xgb_p + (1 - w) * nn_p\n",
    "\n",
    "\n",
    "best_w, best_ap = None, -1\n",
    "for w in np.linspace(0, 1, 21):\n",
    "    ens_val = weighted_ensemble(xgb_cal(xgb_val_proba), nn_cal(nn_val_proba), w)\n",
    "    ap = average_precision_score(y_val, ens_val)\n",
    "    if ap > best_ap:\n",
    "        best_ap, best_w = ap, w\n",
    "\n",
    "print(f\"Best ensemble weight (XGB={best_w:.2f}, NN={1-best_w:.2f}), PR-AUC={best_ap:.4f}\")\n",
    "\n",
    "\n",
    "val_probs_ens = weighted_ensemble(xgb_cal(xgb_val_proba), nn_cal(nn_val_proba), best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9cc57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
